---
title: "Trying out infer"
description: |
  This is ought to be a short blog post, firstly to get to grips with Distill, secondly to try out infer.
author:
  - name: theCed7
    url: https://github.com/theced7
date: 09-12-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Getting started

First things first: Let's load infer and the rest of the _tidyverse_:

```{r echo=TRUE}
library(infer)
library(tidyverse)
```

_Infer_ is a _tidyverse_ package which aims to aid statistical testing. As such, we also need some data to conduct statistical testing on. As it is 2021, we might as well use something coronavirus-related. This download the vast _Our World in Data_ source file and reads it into R. I will also focus on the UK, since it's one of the countries with the most cohesive data available.

```{r echo=TRUE}
#download.file("https://github.com/owid/covid-19-data/raw/master/public/data/owid-covid-data.csv", "owid-covid-data.csv")

data <- read_csv("owid-covid-data.csv", 
                 col_types = cols(date = col_date(format = "%Y-%m-%d")))

data <- data %>%
  filter(iso_code %in% c("GBR", "USA", "DEU")) %>%
  filter(date > "2021-01-01")

glimpse(data)
```

# Starting off with _infer_

The idea of _infer_ is to simplfy statistical testing into four easy steps:

1. `specify()`
2. `hypothesize()`
3. `generate()`
4. `calculate()`

We now go through each of these steps one by one.

## `specify`: What do we want to know?

First of all, we have to clarify what issue we want to test. What variable of our data frame are we interested in? In this blog post we will ask ourselves, whether there was a significant difference between the reported incidence of SARS-Cov-2 cases between Great Britain and the USA. _Has one country had on average less new cases (per million) than the other?_`

So we `filter` the data to compare Great Britain and the USA. Then we `specify` what variables we are interested in. We also declare, what we believe is cause and effect, e. g. the different countries should explain (`explanatory`), why there is a difference in new cases (`response`). 

```{r echo = TRUE}
data %>% 
  filter(iso_code %in% c("GBR", "USA")) %>% 
  specify(explanatory = iso_code, response = new_cases_per_million )
```

## `hypothesize`: declaring the null hypothesis

Secondly, we declare the _null hypothesis_. Statistically speaking, the null hypothesis assumes there _truly_ is no difference (or no correlation). Applied to our example our null hypothesis would be: _There is no significant difference in new SARS-Cov2 cases per million people between the US and the UK._ 

On a side note: We also introduce a new, shorter way of using `specify`. Keep an eye on which order you place the arguments (i. e. column names) in, because that determines which is used as the dependent or independent variable. 

Do not pay a lot of attention on the output our code is generating at this moment. Hopefully, this all comes together shortly. As long as there aren't any errors and you roughly understand the statistical lingo, we should be fine.

```{r echo=TRUE}
data %>% 
  filter(iso_code %in% c("GBR", "USA")) %>% 
  specify(new_cases_per_million ~ iso_code) %>% 
  hypothesize(null = "independence")
```

## `generate`: generating the null distribution

Not quite sure what happens here.

```{r echo=TRUE}
data %>% 
  filter(iso_code %in% c("GBR", "USA")) %>% 
  specify(iso_code ~ new_cases_per_million) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute")
```

## `calculate`: calculating summary statistics

Now that we have some understanding of how to use the infer functions, we try to get back to our original question. 

### Short interlude: Visualization 

Before we move on with facts, figures and infer, let's try to get a rough picture of our question with some basic data visualization. 

```{r echo=TRUE, layout="l-body-outset", fig.height=3}
data %>% 
  filter(iso_code %in% c("GBR", "USA")) %>% 
  ggplot(aes(x = iso_code, y = new_cases_per_million)) +
  geom_jitter(alpha = 0.25) + 
  geom_boxplot(alpha = 0.75) +
  theme_minimal()
```

Here we already see that both medians lie quite close together. So, aren't these countries so different after all?

### Back to infer: t-Test

So, let's `calculate` how big the difference between both medians actually is:

```{r echo = TRUE}
observed_diff_in_medians <- data %>% 
  filter(iso_code %in% c("GBR", "USA")) %>% 
  specify(new_cases_per_million ~ iso_code) %>% 
  calculate(stat = "diff in medians", order = c("USA", "GBR"))

observed_diff_in_medians
```

So, `stat = diff in medians` does what it says: It calculates the difference in medians. The `order` specifies the order of the subtraction (i. e. changes the sign.) 

Just for illustration purposes, we can also try to calculate the difference in medians without infer:

```{r echo=TRUE}
data %>% 
  filter(iso_code %in% c("GBR", "USA")) %>% 
  group_by(iso_code) %>% 
  summarise(
    median = median(new_cases_per_million),
  ) %>% 
  summarise(
    iso_code = iso_code,
    median = median,
    diff = diff(median),
  )
```

But back to infer: We know now the difference between medians of `new_cases_per_million` in both countries equals `r observed_diff_in_medians`. Is this enough do discard our null hypothesis?

Let's use infer to `generate` some data under the assumption, that in fact, _the null hypothesis is **true**_ and there genuinely is _no significant difference_ in new cases between both countries. Then we `calculate` the `diff in medians` for each replicate of the generated data.

```{r echo=TRUE}
null_dist_sample <- data %>% 
  filter(iso_code %in% c("GBR", "USA")) %>% 
  specify(new_cases_per_million ~ iso_code) %>% 
  hypothesise(null = "independence") %>% 
  generate(rep = 1000, type = "permute")

null_dist_sample

null_dist_sample <- null_dist_sample %>% 
  calculate(stat = "diff in medians", order = c("GBR", "USA"))

null_dist_sample
```

Now we can visualize our generated data. Think of it this way: Through some mathematical tricks, infer tried to simulate what our data would look like in a population where the null hypothesis were true.

```{r echo=TRUE}
null_dist_sample %>% 
  visualise()
```

We see a histogram which represents the data of the 1000 reps we generated above. We see that the majority of reps calculated a `diff in medians` somewhere around zero. This makes sense, since this data is ought to be generated in a population where there is no _true_ difference between `new cases` (_null hypothesis_) and all difference there is should be due to random chance.

Now, let's see where in that diagram our _acutal, observed_ difference in medians (`r observed_diff_in_medians`) would fall:

```{r echo=TRUE}
null_dist_sample %>% 
  visualise() +
    shade_p_value(observed_diff_in_medians,
                direction = "two-sided")
```


```{r}
# this calculates the t value
data %>%
  filter(iso_code %in% c("GBR", "USA")) %>% 
  specify(new_cases_per_million ~ iso_code) %>%
  calculate(stat = "t", order = c("GBR", "USA"))
  



null_dist_sample %>% 
  visualize() + 
  shade_p_value(observed_diff_in_medians,
                direction = "two-sided")

p_value_2_sample <- null_dist_sample %>%
  get_p_value(obs_stat = observed_diff_in_medians,
              direction = "two-sided")

p_value_2_sample

t_test(x = data, 
       formula = new_cases_per_million ~ iso_code, 
       order = c("GBR", "USA"),
       alternative = "two-sided")

```

# Another one...

To further strengthen our infer and statistical knowledge, let's look at another country. Maybe Germany had significantly lower cases on average than the USA?

## Charts.

```{r echo=TRUE, layout="l-body-outset", fig.height=3}
data %>% 
  filter(iso_code %in% c("DEU", "USA")) %>% 
  ggplot(aes(x = iso_code, y = new_cases_per_million)) +
  stat_summary(fun=mean, geom="point", size=5, color="red", fill="red") +
  geom_jitter(alpha = 0.25) + 
  geom_boxplot(alpha = 0.75) +
  theme_minimal()
```

On the first glance, it's still a close race, however, there seems to be more of a difference in medians.

We further added a red dot to each box which represents the mean value of `new_cases_per_million` (notice the difference between mean and median). The means seem to be apart even further. 

## Infer

Let's take more in-depth look with infer. Again, we start off by calculating the difference in means which we **observed** in our data. 

Then we let infer **generate** data under the assumption that the reported new cases per million are *independent* of the country they occurred in (null hypothesis). When using `type = permute`, infer does this by reassigning the values of `new_cases_per_million` _by chance_ to either one of the countries. For each `rep`, our entire data get's shuffled once. Thus, a possible link between both variables get's broken.

Subsequently, we also calculate the difference in means for each of our reps. Because we assumed the null hypothesis to be true, this calculation should result in a normal distribution around 0.

```{r echo=TRUE}
# Calculate difference in means in observed data
observed_mean_diff_usa_deu <- data %>% 
  filter(iso_code %in% c("USA", "DEU")) %>% 
  specify(new_cases_per_million ~ iso_code) %>% 
  calculate("diff in means", order = c("USA", "DEU"))

observed_mean_diff_usa_deu

# generate a null distribution based on null hypothesis (independence)
# then calculate the differences in means in that generated "population"
null_dist_usa_deu <- data %>% 
  filter(iso_code %in% c("USA", "DEU")) %>% 
  specify(new_cases_per_million ~ iso_code) %>% 
  hypothesise(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate("diff in means", order = c("USA", "DEU"))

null_dist_usa_deu %>% 
  visualise()
```

We see that the difference in means we _observed_ equals `r round(observed_mean_diff_usa_deu,2)`.

But we might ask ourselves: How sure can we be of this point estimate? Luckily, infer allows us to calculate [confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval):

```{r echo=TRUE}
ci_diff_usa_deu <- null_dist_usa_deu %>% 
  get_confidence_interval(point_estimate = observed_mean_diff_usa_deu,
                          type = "se", # standard error
                          level = .95)

# Visualize the diff in means in generated null distribution 
# and the *observed* diff in means
null_dist_usa_deu %>% 
  visualise() +
  shade_p_value(observed_mean_diff_usa_deu,
                direction = "two-sided") +
  shade_confidence_interval(ci_diff_usa_deu)
```

Already we can see that our observed difference in means if much, much higher than anything we calculated in our data which assumed the null hypothesis.

Thus, the possibility of actually observing a difference in means this large (or larger) in a population where the null hypothesis is true, is very small.

If we wanted to put an exact number on that possibility we could calculate the [p-value](https://en.wikipedia.org/wiki/P-value).


```{r echo=TRUE}
p_value_mean_usa_deu <- null_dist_usa_deu %>% 
  get_p_value(obs_stat = observed_mean_diff_usa_deu,
              direction = "two-sided")

p_value_mean_usa_deu
```

So, in a world where the number of new covid cases was independent of the country they appeared in, the possibility of observing a difference in means of cases by country of `r observed_mean_diff_usa_deu` (or more) would be `r p_value_mean_usa_deu`. 


```{r}
data %>% 
  t_test(formula = new_cases_per_million ~ iso_code,
         direction = "two-sided",
         order = c("USA", "DEU"))
```



